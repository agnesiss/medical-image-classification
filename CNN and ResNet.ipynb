{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ad4b43",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "# check GPU\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"GPU: {num_gpus} device(s) available\")\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"  GPU{i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "    # set default device\n",
    "    torch.cuda.set_device(0)\n",
    "    # set device to GPU\n",
    "    device = torch.device(\"cuda:0\")  # use the first GPU\n",
    "    # set parallel strategy\n",
    "    if num_gpus > 1:\n",
    "        print(\"Multi-GPU Training with DataParallel Strategy\")\n",
    "        parallel_strategy = \"DataParallel\"\n",
    "    else:\n",
    "        parallel_strategy = \"Single GPU\"\n",
    "\n",
    "else:\n",
    "    print(\"can't find GPU，and use CPU\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    parallel_strategy = \"CPU\"\n",
    "\n",
    "print(\"current device:\", device)\n",
    "print(\"strategy:\", parallel_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462dbd2e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class XRayDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dirs, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            img_dirs (list): List of directories containing the images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.labels_frame = pd.read_csv(csv_file)# Read the CSV file with image paths and labels\n",
    "        self.img_dirs = img_dirs# Directory containing image files\n",
    "        self.transform = transform# Optional image transforms (resize, normalize)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame) # Total number of samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image name from the dataframe\n",
    "        img_name = self.labels_frame.iloc[idx, 0]\n",
    "        # Construct the full path to the image\n",
    "        for img_dir in self.img_dirs:\n",
    "            img_path = os.getcwd() + os.path.join(img_dir, img_name)\n",
    "            if os.path.exists(img_path):\n",
    "                # Image exists, break the loop\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                # Load labels as a float tensor (multi-label: each class is 0 or 1)\n",
    "                labels = torch.tensor(self.labels_frame.iloc[idx, 1:].values.astype('float32'))\n",
    "                # Apply transforms if any\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "\n",
    "                return image, labels\n",
    "\n",
    "        # if the image can't be found in all files, the error will be raised\n",
    "        raise FileNotFoundError(f\"{img_name} not found in any of the provided directories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2941cc22",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def filter_invalid_samples(dataset):\n",
    "    \"\"\"filter the invalid samples(None) and return new Subset\"\"\"\n",
    "    valid_indices = []\n",
    "    for idx in range(len(dataset)):\n",
    "        sample = dataset[idx]\n",
    "        if sample is not None:\n",
    "            valid_indices.append(idx)\n",
    "\n",
    "    print(f\"original samples: {len(dataset)}, valid samples: {len(valid_indices)}\")\n",
    "    return Subset(dataset, valid_indices)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),               # Resize to 224x224 (required by CNN)\n",
    "    transforms.ToTensor(),                       # Convert to tensor (value range [0,1])\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],   # Normalize using ImageNet means\n",
    "                         [0.229, 0.224, 0.225])   # and standard deviations\n",
    "])\n",
    "# Define the path to the CSV file and image directory\n",
    "csv_file = './labels.csv'\n",
    "img_dir_1 = '/resized_images_add1'\n",
    "img_dir_2 = '/resized_images_add2'\n",
    "img_dir_3 = '/resized_images/resized_images'\n",
    "img_dirs = [img_dir_3]\n",
    "# Create the dataset\n",
    "dataset = XRayDataset(csv_file=csv_file, img_dirs=img_dirs, transform=transform)\n",
    "filtered_dataset = filter_invalid_samples(dataset)\n",
    "# read the disease names from the CSV file\n",
    "df = pd.read_csv(csv_file)\n",
    "disease_names = df.columns[1:].tolist()  # Skip the first column (image names)\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(filtered_dataset))\n",
    "test_size = len(filtered_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(filtered_dataset, [train_size, test_size])\n",
    "# Create DataLoader for training and validation sets\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13416f1b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=15):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)   # [B, 3, 224, 224] -> [B, 16, 224, 224]\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)                            # -> [B, 16, 112, 112]\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)  # -> [B, 32, 112, 112]\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)                            # -> [B, 32, 56, 56]\n",
    "\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # -> [B, 64, 56, 56]\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)                            # -> [B, 64, 28, 28]\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced97c9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "from sklearn.metrics import f1_score\n",
    "def evaluate_CNN(net, val_loader, disease_names, epoch = None, criterion = nn.BCEWithLogitsLoss()):\n",
    "    net.eval()\n",
    "    device = next(net.parameters()).device\n",
    "\n",
    "    all_targets = []\n",
    "    all_probs = []\n",
    "    all_preds = []\n",
    "    total_correct = torch.zeros(len(disease_names)).to(device)\n",
    "    total_samples = 0\n",
    "    total_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = torch.sigmoid(net(images))\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()*images.size(0)\n",
    "\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            total_correct += (predictions == labels).sum(dim=0)\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            all_targets.append(labels)\n",
    "            all_probs.append(outputs)\n",
    "            all_preds.append(predictions)\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader.dataset)\n",
    "    all_targets = torch.cat(all_targets).cpu().numpy()\n",
    "    all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "\n",
    "    if epoch is None:\n",
    "      accuracy = total_correct / total_samples * 100\n",
    "      print(\"\\n=== Per Disease Accuracy ===\")\n",
    "      for disease, acc in zip(disease_names, accuracy):\n",
    "          print(f\"{disease}: {acc:.2f}%\")\n",
    "      min_idx = accuracy.argmin()\n",
    "      print(f\"=== Worst Performing Disease by accuracy: {disease_names[min_idx]} ({accuracy[min_idx]:.2f}%)\")\n",
    "\n",
    "      print(\"\\n=== Per Disease F1 Score ===\")\n",
    "      f1_scores = f1_score(all_targets, all_preds, average=None, zero_division=0)\n",
    "      for disease, f1 in zip(disease_names, f1_scores):\n",
    "          print(f\"{disease}: {f1:.4f}\")\n",
    "      min_idx = f1_scores.argmin()\n",
    "      print(f\"=== Worst Performing Disease by F1: {disease_names[min_idx]} (F1: {f1_scores[min_idx]:.4f})\")\n",
    "\n",
    "      f1_micro = f1_score(all_targets, all_preds, average=\"micro\", zero_division=0)\n",
    "      f1_macro = f1_score(all_targets, all_preds, average=\"macro\", zero_division=0)\n",
    "      print(f\"\\nF1 Score (Micro): {f1_micro:.4f}\")\n",
    "      print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03603a5a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_CNN(net, train_loader, val_loader, device, num_epochs=20):\n",
    "    criterion = nn.BCEWithLogitsLoss() # Use Binary Cross Entropy for multi-label classification\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.5)\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss_CNN_plot = []\n",
    "    val_loss_CNN_plot = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "        avg_loss = running_loss / len(train_loader.dataset)\n",
    "        train_loss_CNN_plot.append(avg_loss)\n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        val_loss = evaluate_CNN(net, val_loader, disease_names, epoch, criterion)\n",
    "        val_loss_CNN_plot.append(val_loss)\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {avg_loss:.4f}, Validation Loss: {val_loss:.4f}, Time: {elapsed:.2f} min\")\n",
    "\n",
    "baseline_cnn_net = CNN(num_classes=len(disease_names)).to(device)\n",
    "train_CNN(baseline_cnn_net, train_loader, val_loader, device)\n",
    "torch.save(baseline_cnn_net.state_dict(), \"baseline_cnn_net.pth\")\n",
    "print(\"Model saved as baseline_cnn_net.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1159b701",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class ResNet50_MultiLabel(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(ResNet50_MultiLabel, self).__init__()\n",
    "\n",
    "        self.backbone = models.resnet50(pretrained=True)\n",
    "\n",
    "        in_features = self.backbone.fc.in_features\n",
    "\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(0.16),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "resnet = ResNet50_MultiLabel(15).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b96c4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_resnet(resnet, val_loader, criterion = nn.BCEWithLogitsLoss(), epoch=None):\n",
    "    resnet.eval()\n",
    "    total_correct = [0] * 15\n",
    "    total_samples = [0] * 15\n",
    "    total_loss = 0.0\n",
    "\n",
    "    all_labels = [[] for _ in range(15)]\n",
    "    all_probs = [[] for _ in range(15)]\n",
    "    all_preds = [[] for _ in range(15)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = resnet(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predictions = (probs > 0.5).float()\n",
    "\n",
    "            for i in range(15):\n",
    "                total_correct[i] += (predictions[:, i] == labels[:, i]).sum().item()\n",
    "                total_samples[i] += labels[:, i].numel()\n",
    "\n",
    "                all_labels[i].extend(labels[:, i].cpu().numpy())\n",
    "                all_probs[i].extend(probs[:, i].cpu().numpy())\n",
    "                all_preds[i].extend(predictions[:, i].cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader.dataset)\n",
    "\n",
    "    if epoch is None:\n",
    "        print(\"\\n=== Per Disease Accuracy ===\")\n",
    "        acc_list = []\n",
    "        for i, disease in enumerate(disease_names):\n",
    "            accuracy = total_correct[i] / total_samples[i] * 100\n",
    "            acc_list.append(accuracy)\n",
    "            print(f\"{disease}: {accuracy:.2f}%\")\n",
    "\n",
    "        min_idx = acc_list.index(min(acc_list))\n",
    "        print(f\"\\nWorst performing disease: {disease_names[min_idx]} ({acc_list[min_idx]:.2f}%)\")\n",
    "\n",
    "        print(\"\\n=== Per Disease AUC-ROC ===\")\n",
    "        for i, disease in enumerate(disease_names):\n",
    "            try:\n",
    "                auc = roc_auc_score(all_labels[i], all_probs[i])\n",
    "                print(f\"{disease}: AUC = {auc:.4f}\")\n",
    "            except ValueError:\n",
    "                print(f\"{disease}: AUC = N/A (only one class present in labels)\")\n",
    "\n",
    "        print(\"\\n=== Per Disease F1 Score ===\")\n",
    "        f1_scores = f1_score(all_labels, all_preds, average=None, zero_division=0)\n",
    "        for i, disease in enumerate(disease_names):\n",
    "            try:\n",
    "                f1 = f1_score(all_labels[i], all_preds[i])\n",
    "                print(f\"{disease}: F1 = {f1:.4f}\")\n",
    "            except ValueError:\n",
    "                print(f\"{disease}: F1 = N/A (only one class present in labels or predictions)\")\n",
    "        min_idx = f1_scores.argmin()\n",
    "        print(f\"=== Worst Performing Disease by F1: {disease_names[min_idx]} (F1: {f1_scores[min_idx]:.4f})\")\n",
    "\n",
    "        f1_micro = f1_score(all_labels, all_preds, average=\"micro\", zero_division=0)\n",
    "        f1_macro = f1_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "        print(f\"\\nF1 Score (Micro): {f1_micro:.4f}\")\n",
    "        print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n",
    "\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa020423",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_resnet(net, train_loader, val_loader, num_epochs=20):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(resnet.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10, 15], gamma=0.5)\n",
    "\n",
    "    start_time = time.time()\n",
    "    train_loss_resnet_plot = []\n",
    "    val_loss_resnet_plot = []\n",
    "\n",
    "    for epoch in range(0, 20):\n",
    "        resnet.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # Set the gradients to zeros\n",
    "            optimizer.zero_grad()\n",
    "            # forward the minibatch through the net\n",
    "            outputs = resnet(images)\n",
    "            # Compute the average of the losses of the data points in the minibatch\n",
    "            loss = criterion(outputs, labels)\n",
    "            # backward pass to compute dL/dU, dL/dV and dL/dW\n",
    "            loss.backward()\n",
    "            # do one step of stochastic gradient descent\n",
    "            optimizer.step()\n",
    "            # add the loss of this batch to the running loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        train_loss_resnet_plot.append(avg_loss)\n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        val_loss = evaluate_resnet(resnet, val_loader, criterion, epoch)\n",
    "        val_loss_resnet_plot.append(val_loss)\n",
    "        print(f\"\\nEpoch {epoch}, Train Loss: {avg_loss:.4f}, Validation Loss: {val_loss:.4f}, Time: {elapsed:.2f} min\")\n",
    "train_resnet(resnet, train_loader, val_loader, num_epochs=20)\n",
    "torch.save(resnet.state_dict(), \"resnet.pth\")\n",
    "print(\"✅ Model saved as resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f7ca82",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# create a new figure with 1 row and 2 columns\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "# the second subplot：CNN\n",
    "axs[0].plot(train_loss_CNN_plot, label='Train Loss')\n",
    "axs[0].plot(val_loss_CNN_plot, label='Validation Loss')\n",
    "axs[0].set_title('CNN Loss')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend(loc='upper right')\n",
    "#the first subplot：ResNet\n",
    "axs[1].plot(train_loss_resnet_plot, label='Train Loss')\n",
    "axs[1].plot(val_loss_resnet_plot, label='Validation Loss')\n",
    "axs[1].set_title('ResNet Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].legend(loc='upper right')\n",
    "# automatically adjust subplot parameters to give specified padding\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f59f79",
   "metadata": {},
   "source": [
    "# Effect of Image Augmentation and Tranformation\n",
    "Because of the poor performance of the previous model, further tuning was needed to train a better performing model based on the experience of training.\n",
    "\n",
    "1.   Image catalogue update and Image Augmentation\n",
    "\n",
    "Image data that has been processed through Data Augmentation and Image Transform has been added. Refer to the Data Preprocessing section for specific operations.\n",
    "\n",
    "Purpose: To improve the prediction performance on unseen samples by increasing the diversity of samples and mitigating overfitting.\n",
    "2.   Number of training rounds (Epoch) adjustment\n",
    "\n",
    "The number of training rounds is set to 5 epochs.\n",
    "In previous training experiments, the model showed obvious overfitting near the 8th epoch (training loss continued to fall but validation loss rose), so we actively shortened the number of training rounds in the new round of training to avoid the overfitting problem from occurring again.\n",
    "\n",
    "Purpose: To maintain the generalisation ability during training while learning sufficiently, and to improve the stability of the final model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b61b032",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "new_img_dirs = [img_dir_3, img_dir_1, img_dir_2]\n",
    "csv_file = './new_labels.csv'\n",
    "# Create the dataset\n",
    "new_dataset = XRayDataset(csv_file=csv_file, img_dirs=new_img_dirs, transform=transform)\n",
    "\n",
    "# read the disease names from the CSV file\n",
    "new_df = pd.read_csv(csv_file)\n",
    "new_disease_names = new_df.columns[1:].tolist()  # Skip the first column (image names)\n",
    "# Split the dataset into training and validation sets\n",
    "new_train_size = int(0.8 * len(new_dataset))\n",
    "new_test_size = len(new_dataset) - new_train_size\n",
    "new_train_dataset, new_test_dataset = torch.utils.data.random_split(new_dataset, [new_train_size, new_test_size])\n",
    "# Create DataLoader for training and validation sets\n",
    "batch_size = 32\n",
    "new_train_loader = DataLoader(new_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "new_val_loader = DataLoader(new_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# Train with new data\n",
    "full_resnet_net = ResNet50_MultiLabel(15).to(device)\n",
    "train_resnet(full_resnet_net, train_loader, val_loader, num_epochs=5)\n",
    "torch.save(full_resnet_net.state_dict(), \"full_resnet.pth\")\n",
    "print(\"✅ Model saved as full_resnet.pth\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
